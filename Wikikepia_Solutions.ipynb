{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "gt_YLj8hWvXp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gXmEhhC2so5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058b4a18-b812-4d68-8fc8-85cd8f533780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re # regular expression\n",
        "\n",
        "#前處理\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import KFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# from random import randrange, uniform\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# 分類器\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, recall_score\n",
        "from sklearn.metrics import accuracy_score ,roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "5LxZgyn-Z_V8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### a. Data Preprocessing"
      ],
      "metadata": {
        "id": "CnPXrvwkV8r2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzm3AGj17Vzb"
      },
      "outputs": [],
      "source": [
        "columns = ['height', 'weight', 'sleepiness', 'iq', 'fb_friends', 'yt']\n",
        "\n",
        "def data_preprocess(df):\n",
        "\n",
        "  # 刪除沒有要使用的部分\n",
        "  df = df.drop(['star_sign'], axis=1)\n",
        "\n",
        "  df = missing_value_inputation(df)\n",
        "\n",
        "  df = change_outlier(df)\n",
        "\n",
        "  # self_intro的文字處理\n",
        "  df = self_intro_pre(df)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def missing_value_inputation(df):\n",
        "\n",
        "  # 補眾數+label_encoder\n",
        "  df['phone_os'] = df['phone_os'].fillna('Android')\n",
        "\n",
        "  labelencoder = LabelEncoder()\n",
        "  df['phone_os'] = labelencoder.fit_transform(df['phone_os'])\n",
        "\n",
        "  df['yt'] = pd.to_numeric(df['yt'], errors='coerce')\n",
        "  df = median_inputation(df)\n",
        "\n",
        "  return df\n",
        "\n",
        "def median_inputation(df):\n",
        "\n",
        "  for column in columns:\n",
        "    df[column] = df[column].fillna(df[column].median())\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def change_outlier(df):\n",
        "\n",
        "  for column in columns:\n",
        "\n",
        "    mean = df[column].mean()\n",
        "    std = df[column].std()\n",
        "\n",
        "    lower_bound = 0\n",
        "    upper_bound = 500\n",
        "\n",
        "    outliers_indices_1 = np.where(df[column] < lower_bound)\n",
        "    outliers_indices_2 = np.where(df[column] > upper_bound)\n",
        "\n",
        "    df[column].iloc[outliers_indices_1] = '0'\n",
        "    df[column].iloc[outliers_indices_2] = '500'\n",
        "\n",
        "  return df\n",
        "\n",
        "def remove_outliers_by_IQR(df):\n",
        "  print(df.shape)\n",
        "\n",
        "  for column in columns:\n",
        "\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "  print(df.shape)\n",
        "  return df\n",
        "\n",
        "def draw_outlier(df):\n",
        "\n",
        "  sns.boxplot(data=df)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Word Embedding\n"
      ],
      "metadata": {
        "id": "CmhqiJ0XOCY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "import contractions\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stops_eng = set(stopwords.words('english')) #英文停用詞\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "Lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "# step3 fuction\n",
        "def remove(phrase):\n",
        "    phrase = re.sub(r\"<.*?>\", \" \", phrase) #remove tag\n",
        "    phrase = re.sub(r\"[^\\w\\s]\", \" \", phrase) #remove punctuations\n",
        "    phrase = re.sub(r'\\d', \" \", phrase) #remove numbers\n",
        "    return phrase\n",
        "\n",
        "# this is the function of text processing\n",
        "def self_intro_pre(df):\n",
        "    df['self_intro'] = df['self_intro'].astype(str)\n",
        "    # step1:lowercase\n",
        "    df['self_intro'] = df['self_intro'].str.lower()\n",
        "    # step2:decontracting\n",
        "    df['self_intro'] = df['self_intro'].apply(lambda x: contractions.fix(x))\n",
        "    # step3 remove tags, punctuations, numbers\n",
        "    df['self_intro'] = df['self_intro'].apply(remove)\n",
        "    # step4 tokenization\n",
        "    df['self_intro'] = df['self_intro'].str.split()\n",
        "    # step5 stopword removal\n",
        "    for index, row in df.iterrows():\n",
        "        keywords = []\n",
        "        for words in row['self_intro']:\n",
        "            if words not in stops_eng:\n",
        "                keywords.append(words)\n",
        "        df.at[index, 'self_intro'] = keywords\n",
        "    # step6 lemmatization\n",
        "    for index, row in df.iterrows():\n",
        "        Lemma = []\n",
        "        for i in row['self_intro']:\n",
        "            Lemma.append(Lemmatizer.lemmatize(i , pos='v'))\n",
        "        df.at[index, 'self_intro'] = Lemma\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "GzMBZWcFrO8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf8facf-b7be-413f-af00-e3cfa8050f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "#this is the function for tf-idf, need train simultaneously to ensure the selected features are the same\n",
        "#and it returns only 'self_intro' , need to concat with other variable such as weight,yt.... to train the model\n",
        "def calculate_tfidf(train, test):\n",
        "    train['self_intro'] = train['self_intro'].astype(str) #確保都是str\n",
        "    test['self_intro'] = test['self_intro'].astype(str)\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=46) #tf-idf 留頻率出現超過3次的feature(這邊已用counter計算為46個詞)\n",
        "    X_train_tfidf = tfidf_vectorizer.fit_transform(train['self_intro']) #利用此46個feature做tfidf_matrix\n",
        "    X_test_tfidf = tfidf_vectorizer.transform(test['self_intro'])\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out() #46個feature name\n",
        "    # print(feature_names)\n",
        "\n",
        "    # 用卡方檢定做feature selection\n",
        "    k_best = SelectKBest(chi2, k=20)\n",
        "    X_train_tfidf_sel = k_best.fit_transform(X_train_tfidf, train['gender'])\n",
        "    X_test_tfidf_sel = k_best.transform(X_test_tfidf)\n",
        "    selected_features_indices = k_best.get_support(indices=True)\n",
        "    selected_features = [feature_names[i] for i in selected_features_indices]\n",
        "    tfidf_train = pd.DataFrame(X_train_tfidf_sel.toarray(), columns =selected_features)\n",
        "    tfidf_test = pd.DataFrame(X_test_tfidf_sel.toarray(), columns =selected_features)\n",
        "\n",
        "    return tfidf_train, tfidf_test"
      ],
      "metadata": {
        "id": "BJGniquarPoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. Model"
      ],
      "metadata": {
        "id": "Zo9XtR_9Y5hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_random_forest(x_train, y_train, test_data):\n",
        "\n",
        "  rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "  rf.fit(x_train, y_train)\n",
        "  y_pred = rf.predict(test_data)\n",
        "  y_pred = pd.DataFrame(y_pred, columns = [\"gender\"])\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def run_random_forest_acc(x_train, y_train, x_test, y_test):\n",
        "\n",
        "  rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "  rf.fit(x_train, y_train)\n",
        "  y_pred = rf.predict(x_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print('------------rf-------------')\n",
        "  print(acc)\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def run_svm(x_train, y_train, test_data, set_kernel=None):\n",
        "\n",
        "  if set_kernel == None :\n",
        "    set_kernel = 'rbf'\n",
        "\n",
        "  svm = SVC(kernel=set_kernel)\n",
        "\n",
        "  svm.fit(x_train, y_train)\n",
        "  y_pred = svm.predict(test_data)\n",
        "  y_pred = pd.DataFrame(y_pred, columns = [\"gender\"])\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def run_svm_acc(x_train, y_train, x_test, y_test, set_kernel=None):\n",
        "\n",
        "  if set_kernel == None :\n",
        "    set_kernel = 'rbf'\n",
        "\n",
        "  svm = SVC(kernel=set_kernel)\n",
        "\n",
        "  svm.fit(x_train, y_train)\n",
        "  y_pred = svm.predict(x_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print('------------svm-------------')\n",
        "  print(acc)\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "# KNN model\n",
        "def KNN(x_train, y_train, x_test, y_test):\n",
        "  knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "  knn_classifier.fit(x_train, y_train)\n",
        "  knn_y_pred = knn_classifier.predict(x_test)\n",
        "  accuracy = accuracy_score(y_test, knn_y_pred)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "v9EolwYuZFDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "r5leIMZgYdcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/My Drive/Colab Notebooks/datasets/boy/boy or girl 2024 train_missingValue.csv')\n",
        "df_test = pd.read_csv('drive/My Drive/Colab Notebooks/datasets/boy/boy or girl 2024 test no ans_missingValue.csv')\n",
        "\n",
        "#tfidf\n",
        "df_intro, df_test_intro = calculate_tfidf(df, df_test)\n",
        "\n",
        "# 前處理\n",
        "x = data_preprocess(df)\n",
        "df_test = data_preprocess(df_test)\n",
        "\n",
        "y = x['gender']\n",
        "\n",
        "x = x.merge(df_intro, how='left', left_index=True, right_index=True)\n",
        "df_test = df_test.merge(df_test_intro, how='left', left_index=True, right_index=True)\n",
        "x = x.drop(['self_intro', 'gender'], axis=1)\n",
        "df_test = df_test.drop(['self_intro', 'gender'], axis=1)\n",
        "\n",
        "oversample = SMOTE(random_state=42)\n",
        "x, y = oversample.fit_resample(x, y)\n",
        "\n",
        "#分類器\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y);\n",
        "\n",
        "# RandomForest\n",
        "y_pred = run_random_forest_acc(x_train, y_train, x_test, y_test)\n",
        "print(y_pred)\n",
        "y_pred = run_random_forest(x, y, df_test)\n",
        "y_pred.to_csv('/content/drive/My Drive/Colab Notebooks/output/rf.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# svm\n",
        "# y_predict = run_svm_acc(x_train, y_train, x_test, y_test, 'linear')\n",
        "# print(y_predict)\n",
        "# y_predict = run_svm(x, y, df_test, 'linear')\n",
        "# y_predict.to_csv('/content/drive/My Drive/Colab Notebooks/output/svm.csv', index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "eM_mYbkXZc8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8db7774-38b9-4191-a4f2-556a5f6691ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n",
            "<ipython-input-8-bc85b0901037>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[column].iloc[outliers_indices_1] = '0'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------rf-------------\n",
            "0.9291338582677166\n",
            "[[57  7]\n",
            " [ 2 61]]\n",
            "[2 2 1 2 2 1 2 2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 2 1 2 1 2 2 2 1 1 2 2 2 1 2 1\n",
            " 2 1 2 1 2 1 2 2 1 2 1 2 2 1 2 1 1 2 2 1 1 2 1 2 2 2 1 1 2 2 1 2 2 2 2 2 1\n",
            " 2 1 2 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 1 1 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2\n",
            " 1 1 1 2 1 2 1 2 1 1 2 2 1 2 1 1]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}